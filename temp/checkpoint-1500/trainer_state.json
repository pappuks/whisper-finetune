{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.8337408312958434,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03,
      "grad_norm": 1.0819131135940552,
      "learning_rate": 0.0005,
      "loss": 0.7759,
      "step": 25
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.374916911125183,
      "learning_rate": 0.001,
      "loss": 0.7446,
      "step": 50
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.186684489250183,
      "learning_rate": 0.0009896006655574043,
      "loss": 0.6971,
      "step": 75
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.4452191591262817,
      "learning_rate": 0.0009792013311148086,
      "loss": 0.64,
      "step": 100
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.3896161317825317,
      "learning_rate": 0.000968801996672213,
      "loss": 0.6715,
      "step": 125
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.4240458011627197,
      "learning_rate": 0.0009584026622296174,
      "loss": 0.701,
      "step": 150
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.7808431386947632,
      "learning_rate": 0.0009480033277870217,
      "loss": 0.675,
      "step": 175
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1263971328735352,
      "learning_rate": 0.000937603993344426,
      "loss": 0.6566,
      "step": 200
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1162598133087158,
      "learning_rate": 0.0009272046589018303,
      "loss": 0.6452,
      "step": 225
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1096700429916382,
      "learning_rate": 0.0009168053244592346,
      "loss": 0.605,
      "step": 250
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.114863395690918,
      "learning_rate": 0.000906405990016639,
      "loss": 0.6015,
      "step": 275
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.102449655532837,
      "learning_rate": 0.0008960066555740433,
      "loss": 0.595,
      "step": 300
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.424063801765442,
      "learning_rate": 0.0008856073211314476,
      "loss": 0.6229,
      "step": 325
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.5082411766052246,
      "learning_rate": 0.0008760399334442596,
      "loss": 0.6253,
      "step": 350
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1326830387115479,
      "learning_rate": 0.0008656405990016639,
      "loss": 0.5866,
      "step": 375
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2450746297836304,
      "learning_rate": 0.0008552412645590683,
      "loss": 0.6009,
      "step": 400
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0846492052078247,
      "learning_rate": 0.0008448419301164726,
      "loss": 0.5689,
      "step": 425
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.9542080163955688,
      "learning_rate": 0.0008344425956738769,
      "loss": 0.577,
      "step": 450
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.8927016854286194,
      "learning_rate": 0.0008240432612312813,
      "loss": 0.555,
      "step": 475
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.0420866012573242,
      "learning_rate": 0.0008136439267886856,
      "loss": 0.581,
      "step": 500
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.1844749450683594,
      "learning_rate": 0.0008032445923460899,
      "loss": 0.5791,
      "step": 525
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.1146382093429565,
      "learning_rate": 0.0007928452579034942,
      "loss": 0.5509,
      "step": 550
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1009013652801514,
      "learning_rate": 0.0007824459234608985,
      "loss": 0.5496,
      "step": 575
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8241117000579834,
      "learning_rate": 0.0007720465890183029,
      "loss": 0.5396,
      "step": 600
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0541610717773438,
      "learning_rate": 0.0007616472545757071,
      "loss": 0.5258,
      "step": 625
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.9482482075691223,
      "learning_rate": 0.0007512479201331115,
      "loss": 0.5197,
      "step": 650
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.8226978778839111,
      "learning_rate": 0.0007408485856905158,
      "loss": 0.5229,
      "step": 675
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8089142441749573,
      "learning_rate": 0.0007304492512479201,
      "loss": 0.5222,
      "step": 700
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.4214853048324585,
      "learning_rate": 0.0007200499168053245,
      "loss": 0.5474,
      "step": 725
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8540915846824646,
      "learning_rate": 0.0007096505823627288,
      "loss": 0.5124,
      "step": 750
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7645441293716431,
      "learning_rate": 0.0006992512479201332,
      "loss": 0.5159,
      "step": 775
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.9026402831077576,
      "learning_rate": 0.0006888519134775375,
      "loss": 0.5161,
      "step": 800
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6133815050125122,
      "eval_runtime": 507.9924,
      "eval_samples_per_second": 5.697,
      "eval_steps_per_second": 0.713,
      "step": 818
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.01541268825531,
      "learning_rate": 0.0006784525790349417,
      "loss": 0.5083,
      "step": 825
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.7633083462715149,
      "learning_rate": 0.0006680532445923461,
      "loss": 0.4673,
      "step": 850
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.8726000785827637,
      "learning_rate": 0.0006576539101497504,
      "loss": 0.4648,
      "step": 875
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6904476284980774,
      "learning_rate": 0.0006472545757071547,
      "loss": 0.4739,
      "step": 900
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.7538492679595947,
      "learning_rate": 0.0006368552412645591,
      "loss": 0.4738,
      "step": 925
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6923688650131226,
      "learning_rate": 0.0006264559068219634,
      "loss": 0.47,
      "step": 950
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.9241369366645813,
      "learning_rate": 0.0006160565723793678,
      "loss": 0.4774,
      "step": 975
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.8893770575523376,
      "learning_rate": 0.0006056572379367721,
      "loss": 0.4768,
      "step": 1000
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.9139926433563232,
      "learning_rate": 0.0005952579034941764,
      "loss": 0.4465,
      "step": 1025
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.7728625535964966,
      "learning_rate": 0.0005848585690515808,
      "loss": 0.4553,
      "step": 1050
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.5587809085845947,
      "learning_rate": 0.0005744592346089851,
      "loss": 0.4571,
      "step": 1075
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.8681521415710449,
      "learning_rate": 0.0005640599001663895,
      "loss": 0.4702,
      "step": 1100
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.7318689823150635,
      "learning_rate": 0.0005536605657237936,
      "loss": 0.4372,
      "step": 1125
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.7668992280960083,
      "learning_rate": 0.0005432612312811979,
      "loss": 0.4385,
      "step": 1150
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.9040934443473816,
      "learning_rate": 0.0005328618968386023,
      "loss": 0.4339,
      "step": 1175
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6497033834457397,
      "learning_rate": 0.0005224625623960066,
      "loss": 0.4531,
      "step": 1200
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.8148421049118042,
      "learning_rate": 0.000512063227953411,
      "loss": 0.4437,
      "step": 1225
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.1401588916778564,
      "learning_rate": 0.0005016638935108153,
      "loss": 0.4413,
      "step": 1250
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.3485068082809448,
      "learning_rate": 0.0004912645590682196,
      "loss": 0.4363,
      "step": 1275
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.9460586905479431,
      "learning_rate": 0.000480865224625624,
      "loss": 0.4577,
      "step": 1300
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.8342733979225159,
      "learning_rate": 0.0004704658901830283,
      "loss": 0.4383,
      "step": 1325
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.8043859601020813,
      "learning_rate": 0.0004600665557404326,
      "loss": 0.4407,
      "step": 1350
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.7017835378646851,
      "learning_rate": 0.00044966722129783694,
      "loss": 0.4333,
      "step": 1375
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.8026382923126221,
      "learning_rate": 0.0004392678868552413,
      "loss": 0.4326,
      "step": 1400
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.7627292275428772,
      "learning_rate": 0.00042886855241264563,
      "loss": 0.4182,
      "step": 1425
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.6546809673309326,
      "learning_rate": 0.0004184692179700499,
      "loss": 0.4303,
      "step": 1450
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6740251183509827,
      "learning_rate": 0.00040806988352745427,
      "loss": 0.4435,
      "step": 1475
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.4417881965637207,
      "learning_rate": 0.00039767054908485856,
      "loss": 0.4338,
      "step": 1500
    }
  ],
  "logging_steps": 25,
  "max_steps": 2454,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 3.52300303024128e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
